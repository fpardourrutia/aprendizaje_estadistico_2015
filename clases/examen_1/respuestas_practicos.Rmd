---
title: "Ejercicios - solución"
author: "FG"
date: "October 5, 2015"
output: html_document
---

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(glmnet)
library(caret)
```


# Ejercicio 11

```{r}
data(tecator)
head(absorp)
head(endpoints)
```

Construir tabla

```{r}
datos <- absorp %>% data.frame()
datos$proteina <- endpoints[,3]
datos$id <- 1:nrow(datos)
set.seed(288201)
#set.seed(120364)
indices_e <- sample(1:nrow(datos), floor(0.75*nrow(datos)))
datos_e <- datos[indices_e, ]
datos_p <- datos[-indices_e, ]
nrow(datos_e)
nrow(datos_p)
```

La tasa base de error es

```{r}
media_e <- mean(datos_e$proteina)
sqrt(mean((datos_p$proteina-media_e)^2))
```


### Datos

Las columnas son mediciones en distintos puntos de curvas:

```{r}
dat_e <- datos_e %>% dplyr::select(-proteina) %>%
  gather(wl, valor, -id) %>%
  separate(wl, c('x', 'num_1'), 'X') %>%
  mutate(num = as.numeric(num_1))
ggplot(dat_e, aes(x=num, y=valor, group=id)) + geom_line()
```

La correlación de variables es muy alta, por ejemplo,
```{r}
mat_cor <- cor(datos_e %>% dplyr::select(-id,-proteina))
quantile(as.numeric(mat_cor))
```

Usamos primero mínimos cuadrados:

```{r}
mod_mc <- lm(proteina ~ ., datos_e %>% dplyr::select(-id))
preds_mc <- predict(mod_mc, newdata = datos_p)
sqrt(mean((datos_p$proteina - preds_mc)^2))
```

Ahora hacemos vecinos más cercanos (escogiendo con validación cruzada):

```{r}

library(kknn)
control <- trainControl(method = "cv", number = 10)
grid <- expand.grid(list(kmax=c(1,2,3,4,5,6,7,8,9,10), kernel = 'rectangular', distance = 2))
set.seed(84924)
vmc_caret <- train(datos_e %>% dplyr::select(-id, -proteina) , 
                   datos_e$proteina, 
                   method = "kknn", 
                   trControl = control,
                   tuneGrid = grid,
                   preProc = c("center", "scale"))
vmc_caret
vmc_caret$bestTune
```




Y evaluamos

```{r}
preds_vmc <- predict(vmc_caret, new = datos_p %>% dplyr::select(-id, -proteina))
sqrt(mean((preds_vmc - datos_p$proteina)^2))
```

Que tiene peor desempeño que mínimos cuadrados. Ahora hacemos glmnet. 

```{r}
set.seed(221)
alpha = seq(0,1,0.1)
modelos <- lapply(alpha, function(a){
      print(a)
      mod_1 <- cv.glmnet(x = datos_e %>% dplyr::select(-id, -proteina) %>% as.matrix,
                         y = datos_e$proteina, 
                         alpha=a, lambda=exp(seq(-10,1,0.5)),
                         maxit = 6e5)
      list(alpha = a, mod = mod_1)
})

dat_cv <- lapply(modelos, function(x){
  mod = x$mod
  data_frame(cvm = mod$cvm, lambda = mod$lambda, alpha = x$alpha)
} )
head(dat_cv)
dat_g <- bind_rows(dat_cv)
ggplot(dat_g, aes(x=lambda, y=cvm, group=alpha, colour=factor(alpha))) + geom_line() + scale_x_log10()
dat_g[which.min(dat_g$cvm),]
```
 
El desempeño es similar para los distintos tipos de regularización.

```{r}
mod_selec <- modelos[[1]]$mod
plot(mod_selec)
preds <- predict(mod_selec, newx = datos_p %>% dplyr::select(-id, -proteina) %>% as.matrix)
sqrt(mean((preds-datos_p$proteina)^2))
```

Que es comparable al error de  mínimos cuadrados. La diferencia grande,
sin embargo, es la suavidad de los coeficientes:
```{r}
qplot(1:100,coef(mod_selec)[-1], geom="line") + geom_hline(yintercept=0)
qplot(1:100, coef(mod_mc)[-1], geom="line") + geom_hline(yintercept=0)
```
El modelo ridge es más interpretable y parsimonioso. Podemos verificar nuestro hallazgo de los coeficientes:
```{r}
dat_e <- datos_e %>% dplyr::select(-proteina) %>%
  gather(wl, valor, -id) %>%
  separate(wl, c('x', 'num_1'), 'X') %>%
  mutate(num = as.numeric(num_1)) %>% 
  left_join(datos_e %>% dplyr::select(id, proteina))
dat_e$proteina_cat <- cut(dat_e$proteina, breaks=quantile(dat_e$proteina),
                          include.lowest = T)
ggplot(filter(dat_e, num < 40), 
       aes(x=num, y=valor, group=id, colour=proteina_cat)) + geom_line() +
  facet_wrap(~proteina_cat)
```

```{r}
dat_eg <- dat_e %>% 
  mutate(cat_num = cut(num, breaks = c(1,10,20,30,40,50,60,70,80,90,100), include.lowest = T)) %>%
  group_by(id, cat_num) %>%
  summarise(valor_media = mean(valor), proteina_cat=proteina_cat[1]) %>% 
  spread(cat_num, valor_media)
ggplot(dat_eg, aes(x=`[1,10]`, y=`(20,30]`, colour=proteina_cat)) + geom_point(size=3)
ggplot(dat_eg, aes(x=`[1,10]`, y=`(20,30]`/`[1,10]`, colour=proteina_cat)) + geom_point(size=3)
```

### Nota
En este ejemplo la muestra de prueba es bastante chica, así que
tenemos que tener cuidado en interpretarla. Lo mejor es obtener intervalos
de confianza para las estimaciones del error.

Por ejemplo, podríamos hacer:

```{r}
residuales_r <- preds-datos_p$proteina
boot_error <- function(x){
  boot_x <- x[sample(length(x), replace = T)]
  sqrt(mean(boot_x^2))
}
reps <- sapply(1:200, function(i) boot_error(residuales_r))
```

Y el error estándar de nuestra estimación de error para el modelo ridge es de 
```{r}
sd(reps)
```





# Ejercicio 12


```{r}
library(readr)
docs <- readRDS(file = './sentimiento/datos/documentos.rds')
doc_terms <- readRDS(file = './sentimiento/datos/documentos_terminos.rds')
```

```{r}
library(Matrix)
X <- sparseMatrix(i = doc_terms$id_doc, j = doc_terms$id_termino, x = log(1+doc_terms$frec))
y <- docs$polaridad
set.seed(1200)
indices_e <- sample(1:nrow(X), floor(0.75*nrow(X)))
X_e <- X[indices_e,]
y_e <- y[indices_e]
X_p <- X[-indices_e,]
y_p <- y[-indices_e]
cv_1 <- cv.glmnet(x=X_e, y=y_e, alpha=1.0, family = 'binomial', lambda=exp(seq(-10,10,0.5)))
plot(cv_1)
```

```{r}
preds <- predict(cv_1, newx = X_p, type='response')
tab_1 <- table(preds > 0.5, y_p)
(tab_1[1,1]+tab_1[2,2])/sum(tab_1)
prop.table(tab_1, 2)
```

```{r}
library(stringr)
coeficientes <- coef(cv_1)[,1][-1]
id_termino <- rownames(coef(cv_1))[-1] %>% str_sub(start=2) %>% as.integer
coef_1 <- data_frame(coef = coeficientes, id_termino = id_termino)
terminos <- doc_terms %>% group_by(id_termino, termino) %>% summarise(frec_total = sum(frec))
coefs_nom <- coef_1 %>% left_join(terminos)
```

Los coeficientes más fuertes son los siguientes. Nótese que existen varios
términos muy particulares (géneros, actores) asociados a buenas o malas
reseñas. Estos son informativos de positivo/negativo por el contenido:

```{r}
arrange(coefs_nom %>% filter(frec_total > 0), desc(coef)) %>% print(n=15)
arrange(coefs_nom %>% filter(frec_total > 0), coef) %>% print(n=15)
```

Podemos ver términos más generales filtrando por frecuencia de ocurrencia, más
informativos de positivo/negativo por la manera de escribir y los términos generales usados:

```{r}
arrange(coefs_nom %>% filter(frec_total > 200), desc(coef)) %>% print(n=15)
arrange(coefs_nom %>% filter(frec_total > 200), coef) %>% print(n=15)
```